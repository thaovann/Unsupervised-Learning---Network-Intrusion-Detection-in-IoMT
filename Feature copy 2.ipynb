{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Raw_data/benign/Benign_test\\Benign_00068_20230914231014.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Flow ID\n",
      "1: Src IP\n",
      "2: Src Port\n",
      "3: Dst IP\n",
      "4: Dst Port\n",
      "5: Protocol\n",
      "6: timestamp\n",
      "7: Flow Duration\n",
      "8: Tot Fwd Pkts\n",
      "9: Tot Bwd Pkts\n",
      "10: TotLen Fwd Pkts\n",
      "11: TotLen Bwd Pkts\n",
      "12: Fwd Pkt Len Max\n",
      "13: Fwd Pkt Len Min\n",
      "14: Fwd Pkt Len Mean\n",
      "15: Fwd Pkt Len Std\n",
      "16: Bwd Pkt Len Max\n",
      "17: Bwd Pkt Len Min\n",
      "18: Bwd Pkt Len Mean\n",
      "19: Bwd Pkt Len Std\n",
      "20: Flow Byts/s\n",
      "21: Flow Pkts/s\n",
      "22: Flow IAT Mean\n",
      "23: Flow IAT Std\n",
      "24: Flow IAT Max\n",
      "25: Flow IAT Min\n",
      "26: Fwd IAT Tot\n",
      "27: Fwd IAT Mean\n",
      "28: Fwd IAT Std\n",
      "29: Fwd IAT Max\n",
      "30: Fwd IAT Min\n",
      "31: Bwd IAT Tot\n",
      "32: Bwd IAT Mean\n",
      "33: Bwd IAT Std\n",
      "34: Bwd IAT Max\n",
      "35: Bwd IAT Min\n",
      "36: Fwd PSH Flags\n",
      "37: Bwd PSH Flags\n",
      "38: Fwd URG Flags\n",
      "39: Bwd URG Flags\n",
      "40: Fwd Header Len\n",
      "41: Bwd Header Len\n",
      "42: Fwd Pkts/s\n",
      "43: Bwd Pkts/s\n",
      "44: Pkt Len Min\n",
      "45: Pkt Len Max\n",
      "46: Pkt Len Mean\n",
      "47: Pkt Len Std\n",
      "48: Pkt Len Var\n",
      "49: FIN Flag Cnt\n",
      "50: SYN Flag Cnt\n",
      "51: RST Flag Cnt\n",
      "52: PSH Flag Cnt\n",
      "53: ACK Flag Cnt\n",
      "54: URG Flag Cnt\n",
      "55: CWE Flag Count\n",
      "56: ECE Flag Cnt\n",
      "57: Down/Up Ratio\n",
      "58: Pkt Size Avg\n",
      "59: Fwd Seg Size Avg\n",
      "60: Bwd Seg Size Avg\n",
      "61: Fwd Byts/b Avg\n",
      "62: Fwd Pkts/b Avg\n",
      "63: Fwd Blk Rate Avg\n",
      "64: Bwd Byts/b Avg\n",
      "65: Bwd Pkts/b Avg\n",
      "66: Bwd Blk Rate Avg\n",
      "67: Subflow Fwd Pkts\n",
      "68: Subflow Fwd Byts\n",
      "69: Subflow Bwd Pkts\n",
      "70: Subflow Bwd Byts\n",
      "71: Init Fwd Win Byts\n",
      "72: Init Bwd Win Byts\n",
      "73: Fwd Act Data Pkts\n",
      "74: Fwd Seg Size Min\n",
      "75: Active Mean\n",
      "76: Active Std\n",
      "77: Active Max\n",
      "78: Active Min\n",
      "79: Idle Mean\n",
      "80: Idle Std\n",
      "81: Idle Max\n",
      "82: Idle Min\n",
      "83: iat\n",
      "84: arp_operation\n",
      "85: hardware_type\n",
      "86: protocol_type\n",
      "87: sender_mac\n",
      "88: sender_ip\n",
      "89: target_mac\n",
      "90: target_ip\n",
      "91: hardware_address_length\n",
      "92: protocol_address_length\n",
      "93: arp_header_length\n",
      "94: eth_type\n",
      "95: packet_size\n",
      "96: Label\n"
     ]
    }
   ],
   "source": [
    "# Convert column names to a list\n",
    "column_list = data.columns.tolist()\n",
    "\n",
    "# Print column names along with their indices (order)\n",
    "for index, column in enumerate(column_list):\n",
    "    print(f\"{index}: {column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "def aggregate_csv_features(data, chunk_size=1000):\n",
    "    num_rows = len(data)\n",
    "    aggregated_data = []\n",
    "\n",
    "    for i in range(0, num_rows, chunk_size):\n",
    "        chunk = data.iloc[i : i + chunk_size]\n",
    "\n",
    "        # Count the number of packets with SYN and FIN flags\n",
    "        syn_count = chunk[chunk[\"SYN Flag Cnt\"] == 1].shape[0]\n",
    "        fin_count = chunk[chunk[\"FIN Flag Cnt\"] == 1].shape[0]\n",
    "        print(f\"Số gói tin có cờ SYN: {syn_count}\")\n",
    "        print(f\"Số gói tin có cờ FIN: {fin_count}\")\n",
    "\n",
    "        # Count the number of TCP packets\n",
    "        tcp_count = chunk[chunk[\"Protocol\"] == 6].shape[0]\n",
    "        print(f\"Số gói tin TCP: {tcp_count}\")\n",
    "\n",
    "        # Calculate SYN and FIN per TCP ratio, avoid division by zero\n",
    "        SYN_per_TCP = syn_count / tcp_count if tcp_count > 0 else 0\n",
    "        FIN_per_TCP = fin_count / tcp_count if tcp_count > 0 else 0\n",
    "\n",
    "        # Sum of backward and forward packets\n",
    "        totbwd = chunk[\"Tot Bwd Pkts\"].sum()\n",
    "        totfwd = chunk[\"Tot Fwd Pkts\"].sum()\n",
    "\n",
    "        # Calculate backward packets per forward packets ratio, avoid division by zero\n",
    "        bwk_per_fwk = totbwd / totfwd if totfwd > 0 else 0\n",
    "        print(f\"Backward per forward packet ratio: {bwk_per_fwk}\")\n",
    "\n",
    "        # Count ARP operations\n",
    "        arp_1 = chunk[chunk[\"arp_operation\"] == 1].shape[0]\n",
    "        arp_2 = chunk[chunk[\"arp_operation\"] == 2].shape[0]\n",
    "        print(f\"Số gói tin gửi đi: {arp_1}\")\n",
    "        print(f\"Số gói tin phản hồi: {arp_2}\")\n",
    "\n",
    "        # Calculate ARP response rate, avoid division by zero\n",
    "        rate_arp = arp_2 / arp_1 if arp_1 > 0 else 0\n",
    "        print(rate_arp)\n",
    "\n",
    "        # Average number of IP addresses mapped to a MAC address\n",
    "        mac_addresses = chunk[chunk[\"arp_operation\"] == 2][\"sender_mac\"].nunique()\n",
    "        ip_addresses = chunk[chunk[\"arp_operation\"] == 2][\"sender_ip\"].nunique()\n",
    "\n",
    "        # Avoid division by zero\n",
    "        avg_ip_per_mac = ip_addresses / mac_addresses if mac_addresses > 0 else 0\n",
    "        print(f\"Unique MAC addresses: {mac_addresses}\")\n",
    "        print(f\"Unique IP addresses: {ip_addresses}\")\n",
    "        print(f\"Average IPs per MAC: {avg_ip_per_mac}\")\n",
    "\n",
    "        aggregated_features = []\n",
    "\n",
    "        for feature in data.columns:\n",
    "            if feature not in [\n",
    "                \"Source IP\",\n",
    "                \"Destination IP\",\n",
    "                \"Label\",\n",
    "                \"Protocol\",\n",
    "                \"arp_operation\",\n",
    "                \"protocol_type\",\n",
    "                \"sender_mac\",\n",
    "                \"sender_ip\",\n",
    "                \"target_mac\",\n",
    "                \"target_ip\",\n",
    "            ]:\n",
    "                # Convert to numeric and coerce errors to NaN\n",
    "                numeric_values = pd.to_numeric(chunk[feature], errors=\"coerce\")\n",
    "                mean_value = (\n",
    "                    np.nanmean(numeric_values) if len(numeric_values) > 0 else 0\n",
    "                )\n",
    "                std_value = np.nanstd(numeric_values) if len(numeric_values) > 0 else 0\n",
    "                skew_value = (\n",
    "                    0 if len(numeric_values) < 3 else pd.Series(numeric_values).skew()\n",
    "                )\n",
    "                kurtosis_value = (\n",
    "                    0\n",
    "                    if len(numeric_values) < 4\n",
    "                    else pd.Series(numeric_values).kurtosis()\n",
    "                )\n",
    "                median_value = (\n",
    "                    np.nanmedian(numeric_values) if len(numeric_values) > 0 else 0\n",
    "                )\n",
    "\n",
    "                aggregated_features.extend(\n",
    "                    [mean_value, std_value, skew_value, kurtosis_value, median_value]\n",
    "                )\n",
    "\n",
    "        aggregated_features.extend(\n",
    "            [SYN_per_TCP, FIN_per_TCP, bwk_per_fwk, rate_arp, avg_ip_per_mac]\n",
    "        )\n",
    "        aggregated_data.append(aggregated_features)\n",
    "\n",
    "    aggregated_df = pd.DataFrame(aggregated_data)\n",
    "    return aggregated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số gói tin có cờ SYN: 974\n",
      "Số gói tin có cờ FIN: 7\n",
      "Số gói tin TCP: 987\n",
      "Backward per forward packet ratio: 0.9297752808988764\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 980\n",
      "Số gói tin có cờ FIN: 3\n",
      "Số gói tin TCP: 990\n",
      "Backward per forward packet ratio: 0.954136690647482\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 60\n",
      "Số gói tin có cờ FIN: 0\n",
      "Số gói tin TCP: 60\n",
      "Backward per forward packet ratio: 1.0\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 978\n",
      "Số gói tin có cờ FIN: 9\n",
      "Số gói tin TCP: 991\n",
      "Backward per forward packet ratio: 0.8862068965517241\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 976\n",
      "Số gói tin có cờ FIN: 13\n",
      "Số gói tin TCP: 997\n",
      "Backward per forward packet ratio: 0.9346689895470384\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 47\n",
      "Số gói tin có cờ FIN: 27\n",
      "Số gói tin TCP: 73\n",
      "Backward per forward packet ratio: 0.8421052631578947\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 979\n",
      "Số gói tin có cờ FIN: 2\n",
      "Số gói tin TCP: 989\n",
      "Backward per forward packet ratio: 0.704\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 738\n",
      "Số gói tin có cờ FIN: 12\n",
      "Số gói tin TCP: 758\n",
      "Backward per forward packet ratio: 0.9276974416017798\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 0\n",
      "Số gói tin có cờ FIN: 19\n",
      "Số gói tin TCP: 34\n",
      "Backward per forward packet ratio: 0.21829268292682927\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 0\n",
      "Số gói tin có cờ FIN: 6\n",
      "Số gói tin TCP: 17\n",
      "Backward per forward packet ratio: 0.21188811188811188\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 923\n",
      "Số gói tin có cờ FIN: 18\n",
      "Số gói tin TCP: 981\n",
      "Backward per forward packet ratio: 0.9109739973556633\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 78\n",
      "Số gói tin có cờ FIN: 36\n",
      "Số gói tin TCP: 117\n",
      "Backward per forward packet ratio: 0.7189349112426036\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 894\n",
      "Số gói tin có cờ FIN: 26\n",
      "Số gói tin TCP: 963\n",
      "Backward per forward packet ratio: 0.8937093275488069\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 121\n",
      "Số gói tin có cờ FIN: 50\n",
      "Số gói tin TCP: 183\n",
      "Backward per forward packet ratio: 0.6423611111111112\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n",
      "Số gói tin có cờ SYN: 0\n",
      "Số gói tin có cờ FIN: 21\n",
      "Số gói tin TCP: 31\n",
      "Backward per forward packet ratio: 0.5338983050847458\n",
      "Số gói tin gửi đi: 0\n",
      "Số gói tin phản hồi: 0\n",
      "0\n",
      "Unique MAC addresses: 0\n",
      "Unique IP addresses: 0\n",
      "Average IPs per MAC: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1741: RuntimeWarning: invalid value encountered in subtract\n",
      "  np.subtract(arr, avg, out=arr, casting='unsafe', where=where)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:1248: RuntimeWarning: invalid value encountered in subtract\n",
      "  adjusted = values - mean\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\nanops.py:1336: RuntimeWarning: invalid value encountered in subtract\n",
      "  adjusted = values - mean\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"Raw_data/recon/VulScan/*/*.csv\")\n",
    "aggregated_results = []\n",
    "final_df = []\n",
    "for indx, file in enumerate(files):\n",
    "    data = pd.read_csv(file, low_memory=False)\n",
    "    data = data.drop(\n",
    "        columns=[\n",
    "            \"Label\",\n",
    "            \"Flow ID\",\n",
    "            \"Src IP\",\n",
    "            \"Src Port\",\n",
    "            \"Dst IP\",\n",
    "            \"Dst Port\",\n",
    "            \"Timestamp\",\n",
    "            \"hardware_type\",\n",
    "            \"hardware_address_length\",\n",
    "            \"protocol_address_length\",\n",
    "            \"arp_header_length\",\n",
    "            \"eth_type\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    aggregated_df = aggregate_csv_features(data)\n",
    "    # Add Label column with value 1 (attack category)\n",
    "\n",
    "    aggregated_results.append(aggregated_df)\n",
    "    aggregated_df[\"Label\"] = 1\n",
    "\n",
    "# Concatenate all the results\n",
    "final_df = pd.concat(aggregated_results, ignore_index=True)\n",
    "\n",
    "# Save the final dataframe to a CSV file\n",
    "final_df.to_csv(\"New_Data/RECON_VULSCAN.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame\n",
    "columns_str = \", \".join(data.columns)\n",
    "# Assuming 'data' is your DataFrame\n",
    "for idx, col in enumerate(data.columns, start=1):\n",
    "    print(f\"{idx}: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "# Aggregation function\n",
    "def aggregate_csv_features(data, chunk_size=1000):\n",
    "    aggregated_data = []\n",
    "\n",
    "    # Count the number of packets with SYN and FIN flags\n",
    "    syn_count = data[data[\"SYN Flag Cnt\"] == 1].shape[0]\n",
    "    fin_count = data[data[\"FIN Flag Cnt\"] == 1].shape[0]\n",
    "\n",
    "    # Count the number of TCP packets\n",
    "    tcp_count = data[data[\"Protocol\"] == 6].shape[0]\n",
    "\n",
    "    # Calculate SYN and FIN per TCP ratio, avoid division by zero\n",
    "    SYN_per_TCP = syn_count / tcp_count if tcp_count > 0 else 0\n",
    "    FIN_per_TCP = fin_count / tcp_count if tcp_count > 0 else 0\n",
    "\n",
    "    # Sum of backward and forward packets\n",
    "    totbwd = data[\"Tot Bwd Pkts\"].sum()\n",
    "    totfwd = data[\"Tot Fwd Pkts\"].sum()\n",
    "\n",
    "    # Calculate backward packets per forward packets ratio, avoid division by zero\n",
    "    bwk_per_fwk = totbwd / totfwd if totfwd > 0 else 0\n",
    "\n",
    "    # Count ARP operations\n",
    "    arp_1 = data[data[\"arp_operation\"] == 1].shape[0]\n",
    "    arp_2 = data[data[\"arp_operation\"] == 2].shape[0]\n",
    "\n",
    "    rate_arp = arp_2 / arp_1 if arp_1 > 0 else 0\n",
    "\n",
    "    mac_addresses = data[data[\"arp_operation\"] == 2][\"sender_mac\"].nunique()\n",
    "    ip_addresses = data[data[\"arp_operation\"] == 2][\"sender_ip\"].nunique()\n",
    "\n",
    "    avg_ip_per_mac = ip_addresses / mac_addresses if mac_addresses > 0 else 0\n",
    "\n",
    "    aggregated_features = []\n",
    "\n",
    "    for feature in data.columns:\n",
    "        if feature not in [\n",
    "            \"Source IP\",\n",
    "            \"Destination IP\",\n",
    "            \"Label\",\n",
    "            \"Protocol\",\n",
    "            \"arp_operation\",\n",
    "            \"protocol_type\",\n",
    "            \"sender_mac\",\n",
    "            \"sender_ip\",\n",
    "            \"target_mac\",\n",
    "            \"target_ip\",\n",
    "        ]:\n",
    "\n",
    "            numeric_values = pd.to_numeric(data[feature], errors=\"coerce\")\n",
    "            mean_value = np.nanmean(numeric_values) if len(numeric_values) > 0 else 0\n",
    "            std_value = np.nanstd(numeric_values) if len(numeric_values) > 0 else 0\n",
    "            skew_value = (\n",
    "                0 if len(numeric_values) < 3 else pd.Series(numeric_values).skew()\n",
    "            )\n",
    "            kurtosis_value = (\n",
    "                0 if len(numeric_values) < 4 else pd.Series(numeric_values).kurtosis()\n",
    "            )\n",
    "            median_value = (\n",
    "                np.nanmedian(numeric_values) if len(numeric_values) > 0 else 0\n",
    "            )\n",
    "\n",
    "            aggregated_features.extend(\n",
    "                [mean_value, std_value, skew_value, kurtosis_value, median_value]\n",
    "            )\n",
    "\n",
    "    aggregated_features.extend(\n",
    "        [SYN_per_TCP, FIN_per_TCP, bwk_per_fwk, rate_arp, avg_ip_per_mac]\n",
    "    )\n",
    "    aggregated_data.append(aggregated_features)\n",
    "\n",
    "    aggregated_df = pd.DataFrame(aggregated_data)\n",
    "    return aggregated_df\n",
    "\n",
    "files = glob.glob(\"ATTACK/Train/Dos/UDP/*/*.csv\")\n",
    "aggregated_results = []\n",
    "\n",
    "for indx, file in enumerate(files):\n",
    "    data = pd.read_csv(file, low_memory=False)\n",
    "    data = data.drop(\n",
    "        columns=[\n",
    "            \"Label\",\n",
    "            \"Flow ID\",\n",
    "            \"Src IP\",\n",
    "            \"Src Port\",\n",
    "            \"Dst IP\",\n",
    "            \"Dst Port\",\n",
    "            \"Timestamp\",\n",
    "            \"hardware_type\",\n",
    "            \"hardware_address_length\",\n",
    "            \"protocol_address_length\",\n",
    "            \"arp_header_length\",\n",
    "            \"eth_type\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    aggregated_df = aggregate_csv_features(data)\n",
    "    aggregated_df[\"Label\"] = 1  \n",
    "    aggregated_results.append(aggregated_df)\n",
    "\n",
    "final_df = pd.concat(aggregated_results, ignore_index=True)\n",
    "final_df.to_csv(f\"New_Data/hehe/dos_UDP.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "def aggregate_csv_features(data):\n",
    "    # Average number of IP addresses mapped to a MAC address\n",
    "    mac_addresses = data[data[\"arp_operation\"] == 2][\"sender_mac\"].nunique()\n",
    "    ip_addresses = data[data[\"arp_operation\"] == 2][\"sender_ip\"].nunique()\n",
    "\n",
    "    avg_ip_per_mac = ip_addresses / mac_addresses if mac_addresses > 0 else 0\n",
    "\n",
    "    return avg_ip_per_mac\n",
    "\n",
    "\n",
    "# Array to store average IPs per MAC for each file\n",
    "avg_ip_per_mac_array = []\n",
    "\n",
    "# List all CSV files in the directory\n",
    "files = glob.glob(\"ATTACK/Train/*/*.csv\")\n",
    "\n",
    "# Process each file\n",
    "for file in files:\n",
    "    data = pd.read_csv(file, low_memory=False)\n",
    "\n",
    "    # Drop non-numeric or unnecessary columns\n",
    "    data = data.drop(\n",
    "        columns=[\n",
    "            \"Label\",\n",
    "            \"Flow ID\",\n",
    "            \"Src IP\",\n",
    "            \"Src Port\",\n",
    "            \"Dst IP\",\n",
    "            \"Dst Port\",\n",
    "            \"Timestamp\",\n",
    "            \"hardware_type\",\n",
    "            \"hardware_address_length\",\n",
    "            \"protocol_address_length\",\n",
    "            \"arp_header_length\",\n",
    "            \"eth_type\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Calculate the average IPs per MAC\n",
    "    avg_ip_per_mac = aggregate_csv_features(data)\n",
    "    avg_ip_per_mac_array.append(avg_ip_per_mac)\n",
    "\n",
    "# Load the benign.csv file\n",
    "benign_data = pd.read_csv(\"New_Data/test1.csv\")\n",
    "benign_data = benign_data.drop(columns=[\"Label1\"])\n",
    "# Append the calculated averages as a new column\n",
    "benign_data[\"399\"] = avg_ip_per_mac_array\n",
    "\n",
    "# Add a column \"Label1\" with a constant value of 0\n",
    "benign_data[\"Label1\"] = 1\n",
    "\n",
    "benign_data.to_csv(\"New_Data/test1_updated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "files = glob.glob(\"New_Data/*.csv\")\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "benign_data = pd.concat(dataframes, ignore_index=True)\n",
    "print(benign_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_data = benign_data.drop(columns=[\"Label1\"])\n",
    "# Append the calculated averages as a new column\n",
    "benign_data[\"399\"] = avg_ip_per_mac_array\n",
    "\n",
    "# Add a column \"Label1\" with a constant value of 0\n",
    "benign_data[\"Label1\"] = 1\n",
    "\n",
    "benign_data.to_csv(\"New_Data/train_updated.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_data.to_csv(f\"New_Data/benign.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "files = glob.glob(\"New_Data/6/6/*.csv\")\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "test1_data = pd.concat(dataframes, ignore_index=True)\n",
    "print(test1_data)\n",
    "test1_data.to_csv(f\"New_Data/6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "files = glob.glob(\"New_Data/*.csv\")\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    dataframes.append(df)\n",
    "\n",
    "data = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinity values with a large number\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "#  Fill NaN values with 0 \n",
    "data.fillna(0, inplace=True)\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Label1\"])\n",
    "y = data[\"Label1\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "new_data = X_scaled_df.copy()\n",
    "new_data[\"Label\"] = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(\"data2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trích xuất label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"New_binary_label_data_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"395\",\"396\",\"397\",\"398\",\"399\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"359_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "label_counts = data[\"Label\"].value_counts()\n",
    "\n",
    "# Plotting the value counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "label_counts.plot(kind=\"bar\")\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title(\"Counts of Unique Labels in 'Label' Column\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xticks(rotation=45)  # Rotate labels for better readability\n",
    "plt.grid(axis=\"y\")  # Add a horizontal grid\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [col for col in data.columns if data[col].nunique() == 1]\n",
    "\n",
    "data_cleaned = data.drop(columns=columns_to_drop)\n",
    "print(f\"Các cột đã bị loại bỏ: {columns_to_drop}\")\n",
    "\n",
    "data_cleaned.to_csv(\"New_binary_label_data_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
